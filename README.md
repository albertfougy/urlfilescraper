# URL File Scraper


We want to take our web page performance metrics script from being just a little
script that handles 1 "hard coded" url, to a full blown testing tool.

Step 1:
Remove the "hard coded" url that I was currently using in my last script.

Run my script - it will fail :-)

Step 2:
Make a file that has 1 url in it.  Call it something like urls.txt

Step 3:
Read the urls from that file.  How?  I recommend Googling:

"Ruby bastards reading a file"

Make it so my script pass again like it was.

Step 4:
Add 3 more urls to the urls.txt file and then get my script to pass.

NOTE: I need to modify my script some and make sure the email includes the
performance metrics for each url that was in the urls.txt file.

If I can do the above ( it will be challenging ), I can honestly say that
I know the "basics of coding"!